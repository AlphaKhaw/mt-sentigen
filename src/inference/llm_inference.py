import logging
from typing import Dict, List, Union

from colorama import Fore, Style, init
from gpt4all import GPT4All

init(autoreset=True)

logging.warnings.filterwarnings("ignore")
logging.basicConfig(level=logging.INFO)


def custom_log(msg: str, color: str):
    logging.info(color + msg + Style.RESET_ALL)


def predict(
    model: GPT4All,
    model_name: str,
    input_reviews: Union[List[str], str],
    config: dict,
    is_single_input: bool,
) -> Union[List[Dict[str, Union[str, str]]], Dict[str, Union[str, str]]]:
    """
    Generate predictions based on input reviews using the specified model.

    Parameters:
        model (GPT4All): The language model to be used for prediction.
        model_name (str): The name of the model.
        input_reviews (Union[List[str], str]): A list of reviews or a single
            review for which predictions will be made.
        config (dict): The configuration settings for generating the
            predictions.
        is_single_input (bool): Whether a single input is provided or a list.

    Returns:
        Union[List[Dict[str, Union[str, str]]], Dict[str, Union[str, str]]]:
            - If a list of reviews is provided, returns a list of dictionaries
              with the predictions.
            - If a single review is provided, returns a dictionary with the
              prediction.
    """
    if is_single_input:
        prompt = config["prompts"][model_name]["instruction"].replace(
            "{review}", input_reviews
        )
        output = model.generate(
            prompt, max_tokens=config["generate_parameters"]["max_tokens"]
        ).strip()
        processed_output = post_process_output(output)
        return {input_reviews: processed_output}
    else:
        results = {}
        for review in input_reviews:
            prompt = config["prompts"][model_name]["instruction"].replace(
                "{review}", review
            )
            output = model.generate(
                prompt, max_tokens=config["generate_parameters"]["max_tokens"]
            ).strip()
            processed_output = post_process_output(output)
            results[review] = processed_output
            custom_log(f"Review: {review}", Fore.BLUE)
            custom_log(
                f"Sentiment: {processed_output['sentiment']}", Fore.GREEN
            )
            custom_log(
                f"Generated Response: {processed_output['response']}",
                Fore.GREEN,
            )

        return results


def post_process_output(output: str) -> Dict[str, Union[str, str]]:
    """
    Post-process the output generated by the model.

    Parameters:
        output (str): The raw output string generated by the model.

    Returns:
        Dict[str, Union[str, str]]: A dictionary containing the processed
            output, including the sentiment and response.

    Raises:
        ValueError: If the output is invalid or empty.
    """
    if not isinstance(output, str) or not output:
        raise ValueError("Invalid output")

    if not output.endswith("}"):
        output += "}"

    try:
        processed_output = eval(output)
    except Exception as e:
        logging.error(f"Failed to evaluate output: {e}")
        raise

    processed_output = eval(output)
    return {
        "sentiment": processed_output.get("sentiment", "Unknown"),
        "response": processed_output.get("response", "Unknown"),
    }
